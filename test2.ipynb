{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cant handle multiple consecutive request in a single query. \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, pydantic_function_tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "\n",
    "AIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\")\n",
    "API_BASE_URL = \"https://aiproxy.sanand.workers.dev/openai/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=AIPROXY_TOKEN,\n",
    "    base_url=API_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstallAndRunDatagen(BaseModel):\n",
    "    \"\"\"Model for installing dependencies (if required) and running a Python script.\"\"\"\n",
    "    script_url: str = Field(...,\n",
    "        description=\"URL to the Python script to be downloaded and executed.\"\n",
    "    )\n",
    "\n",
    "    email : str = Field(...,\n",
    "        description=\"The email that is passed as the argument\"\n",
    "    )\n",
    "\n",
    "class FormatMarkdownUsingPrettier(BaseModel):\n",
    "    \"\"\"Model for formatting a Markdown file using Prettier.\"\"\"\n",
    "    file_path: str = Field(..., description=\"Path to the Markdown file to be formatted.\")\n",
    "    prettier_version: str = Field(..., description=\"Version of Prettier to use for formatting. Return Example: 3.4.2 \")\n",
    "\n",
    "\n",
    "class CountTheNumberofDaysAndSave(BaseModel):\n",
    "    day: str = Field(..., description=\"Name of the day\")\n",
    "    input_file: str = Field(..., description=\"Path to the file containing a list of dates.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the count of the days.\")\n",
    "\n",
    "#maybe changed to sort files\n",
    "class SortContacts(BaseModel):\n",
    "    input_file: str = Field(..., description=\"Path to the JSON file containing contacts.\")\n",
    "    output_file: str = Field(..., description=\"Path to the JSON file to write the sorted contacts.\")\n",
    "    sort_keys: List[str] = Field(..., description=\"List of keys to sort by, in order of priority.\")\n",
    "\n",
    "\n",
    "#maybe changed to handle other extension as well\n",
    "class WriteRecentLogs(BaseModel):\n",
    "    directory: str = Field(..., description=\"Path to the directory containing log files.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the recent logs.\")\n",
    "    num_files: int = Field(..., description=\"Number of recent files to process.\")\n",
    "    num_lines: int = Field(..., description=\"Number of lines to extract from each file.\")\n",
    "    extension: str = Field(..., description=\"File extension to filter by, e.g., '.log'.\")\n",
    "\n",
    "#List\n",
    "class GenerateMarkdownIndex(BaseModel):\n",
    "    directory: str = Field(..., description=\"Path to the directory containing Markdown files.\")\n",
    "    output_file: str = Field(..., description=\"Path to the JSON file to write the index.\")\n",
    "    tags: List[str] = Field(..., description=\"List of Markdown tags to extract, e.g., ['#', '##'].\")\n",
    "\n",
    "#maybe changed to pass general text to llm\n",
    "class ExtractUsingLLM(BaseModel):\n",
    "    input_file: str = Field(..., description=\"Path to the file containing the text to be processed.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the extracted information.\")\n",
    "    instructions: str = Field(..., \n",
    "                              description=\"\"\"Instructions for the LLM to extract the desired information.\n",
    "                              Follow the Instruction exactlty. Example: If it says to JUST extract the email: Remember to prompt the tool to just output the email and nothing else.\n",
    "                              \"\"\")\n",
    "\n",
    "\n",
    "class ExtractTextFromImageUsingLLM(BaseModel):\n",
    "    \"Model to extract information from image using LLM\"\n",
    "    input_image: str = Field(..., description=\"Path to the image file.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the extracted text.\")\n",
    "\n",
    "\n",
    "class FindSimilarityUsingEmbeddings(BaseModel):\n",
    "    \"Model to find similarality using embeddings\"\n",
    "    input_file: str = Field(..., description=\"Path to the file containing the text that we need to find the similarity of.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the most similar pair of text.\")\n",
    "\n",
    "\n",
    "class CalculateGoldTicketSales(BaseModel):\n",
    "    database_file: str = Field(..., description=\"Path to the SQLite database file.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the total sales.\")\n",
    "\n",
    "\n",
    "class FetchDataFromAPI(BaseModel):\n",
    "    \"\"\"Model for fetching data from an API and saving it to a file.\"\"\"\n",
    "    api_url: str = Field(..., description=\"The URL of the API to fetch data from.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to save the fetched data.\")\n",
    "\n",
    "\n",
    "class CloneGitRepoAndCommit(BaseModel):\n",
    "    \"\"\"Model for cloning a Git repository and making a commit.\"\"\"\n",
    "    repo_url: str = Field(..., description=\"The URL of the Git repository to clone.\")\n",
    "    commit_message: str = Field(..., description=\"The commit message for the changes.\")\n",
    "    file_path: Optional[str] = Field(None, description=\"Path to the file to modify before committing.\")\n",
    "    file_content: Optional[str] = Field(None, description=\"Content to write to the file before committing.\")\n",
    "\n",
    "\n",
    "class RunSQLQueryOnSQliteDuckDB(BaseModel):\n",
    "    \"\"\"Model for running a SQL query on a SQLite or DuckDB database.\"\"\"\n",
    "    database_file: str = Field(..., description=\"Path to the SQLite or DuckDB database file.\")\n",
    "    query: str = Field(..., description=\"The SQL query to execute.\")\n",
    "    output_file: Optional[str] = Field(None, description=\"Path to the file to save query results (optional).\")\n",
    "\n",
    "\n",
    "class ExtractDataFromWebsite(BaseModel):\n",
    "    \"\"\"Model for extracting data from (i.e. scraping) a website.\"\"\"\n",
    "    website_url: str = Field(..., description=\"The URL of the website to scrape.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to save the scraped data.\")\n",
    "    css_selector: Optional[str] = Field(None, description=\"CSS selector to target specific elements (optional).\")\n",
    "\n",
    "\n",
    "class CompressOrResizeImage(BaseModel):\n",
    "    \"\"\"Model for compressing or resizing an image.\"\"\"\n",
    "    input_image: str = Field(..., description=\"Path to the input image file.\")\n",
    "    output_image: str = Field(..., description=\"Path to the output image file.\")\n",
    "    width: Optional[int] = Field(None, description=\"Target width for resizing (optional).\")\n",
    "    height: Optional[int] = Field(None, description=\"Target height for resizing (optional).\")\n",
    "    quality: Optional[int] = Field(None, description=\"Quality level for compression (1-100, optional).\")\n",
    "\n",
    "\n",
    "class TranscribeAudio(BaseModel):\n",
    "    \"\"\"Model for transcribing audio from an MP3 file.\"\"\"\n",
    "    audio_file: str = Field(..., description=\"Path to the MP3 audio file to transcribe.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to save the transcription text.\")\n",
    "\n",
    "\n",
    "class ConvertMarkdownToHTML(BaseModel):\n",
    "    \"\"\"Model for converting Markdown to HTML.\"\"\"\n",
    "    markdown_file: str = Field(..., description=\"Path to the Markdown file to convert.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to save the converted HTML.\")\n",
    "\n",
    "\n",
    "class WriteAPIEndpointForCSVFilter(BaseModel):\n",
    "    \"\"\"Model for writing an API endpoint that filters a CSV file and returns JSON data.\"\"\"\n",
    "    csv_file: str = Field(..., description=\"Path to the CSV file to filter.\")\n",
    "    filter_column: str = Field(..., description=\"The column name to filter data on.\")\n",
    "    filter_value: str = Field(..., description=\"The value to filter the column by.\")\n",
    "    output_file: Optional[str] = Field(None, description=\"Path to save the filtered JSON data (optional).\")\n",
    "\n",
    "class Execute_shell_command(BaseModel):\n",
    "    command: str = Field(..., description=\"Shell commnands to execute in the terminal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # A\n",
    "    pydantic_function_tool(InstallAndRunDatagen),\n",
    "    pydantic_function_tool(FormatMarkdownUsingPrettier),\n",
    "    pydantic_function_tool(CountTheNumberofDaysAndSave),\n",
    "    pydantic_function_tool(SortContacts),\n",
    "    pydantic_function_tool(WriteRecentLogs),\n",
    "    pydantic_function_tool(GenerateMarkdownIndex),\n",
    "    pydantic_function_tool(ExtractUsingLLM),\n",
    "    pydantic_function_tool(ExtractTextFromImageUsingLLM),\n",
    "    pydantic_function_tool(FindSimilarityUsingEmbeddings),\n",
    "    pydantic_function_tool(CalculateGoldTicketSales),\n",
    "    # B\n",
    "    pydantic_function_tool(FetchDataFromAPI),\n",
    "    pydantic_function_tool(CloneGitRepoAndCommit),\n",
    "    pydantic_function_tool(RunSQLQueryOnSQliteDuckDB),\n",
    "    pydantic_function_tool(ExtractDataFromWebsite),\n",
    "    pydantic_function_tool(CompressOrResizeImage),\n",
    "    pydantic_function_tool(TranscribeAudio),\n",
    "    pydantic_function_tool(ConvertMarkdownToHTML),\n",
    "    pydantic_function_tool(WriteAPIEndpointForCSVFilter),\n",
    "    pydantic_function_tool(Execute_shell_command)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "`/data/email.txt` contains an email message. Pass the content to an LLM with instructions to extract the sender's email address, and write just the email address to `/data/email-sender.txt`\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" \n",
    "You are an AI assistant that helps with various tasks. Use the provided functions to complete the user's request.\n",
    "\n",
    "Guidelines:\n",
    "1. Always check whether a tool or dependency is installed before running any command. If it is missing, install it first using the appropriate package manager.\n",
    "3. Ensure commands are safe and do not exfiltrate data outside `/data`. You must never delete files or data outside `/data`.\n",
    "5. Always verify ambiguous terms in the task description.\n",
    "   - For example, ensure 'uv' refers to the package manager and not `uvicorn`.\n",
    "6. Tasks may be in different languages. Always interpret them correctly.\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": task}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    parallel_tool_calls=False,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-B0b2shlsVMRfh7chx1zwGrPnIg34r', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_IXTMJCBDYQof2ZOobXbzgt7m', function=Function(arguments='{\"input_file\":\"/data/email.txt\",\"output_file\":\"/data/email-sender.txt\",\"instructions\":\"Just extract the sender\\'s email address and nothing else.\"}', name='ExtractUsingLLM'), type='function')]))], created=1739482102, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_72ed7ab54c', usage=CompletionUsage(completion_tokens=46, prompt_tokens=1884, total_tokens=1930, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), monthlyCost=0.15577199999999983, cost=0.005928, monthlyRequests=127)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  ExtractUsingLLM\n",
      "Args:  {'input_file': '/data/email.txt', 'output_file': '/data/email-sender.txt', 'instructions': \"Just extract the sender's email address and nothing else.\"}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    print(\"Name: \", name)\n",
    "    print(\"Args: \", args)\n",
    "    # result = execute_shell(args)\n",
    "    # messages.append({\n",
    "    #     \"role\": \"tool\",\n",
    "    #     \"tool_call_id\": tool_call.id,\n",
    "    #     \"content\": result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': \" \\nYou are an AI assistant that helps with various tasks. Use the provided functions to complete the user's request.\\n\\nGuidelines:\\n1. Always check whether a tool or dependency is installed before running any command. If it is missing, install it first using the appropriate package manager.\\n3. Ensure commands are safe and do not exfiltrate data outside `/data`. You must never delete files or data outside `/data`.\\n5. Always verify ambiguous terms in the task description.\\n   - For example, ensure 'uv' refers to the package manager and not `uvicorn`.\\n6. Tasks may be in different languages. Always interpret them correctly.\\n\\n\\n\"},\n",
       " {'role': 'user',\n",
       "  'content': '\\nInstall uv (if required) and run https://raw.githubusercontent.com/sanand0/tools-in-data-science-public/tds-2025-01/project-1/datagen.py with hello@gmail.com as the only argument.\\n'},\n",
       " {'role': 'tool',\n",
       "  'tool_call_id': 'call_OmmqA0s1CMw1jkQroftnQVHV',\n",
       "  'content': 'WARNING: Package(s) not found: uv'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
