{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cant handle multiple consecutive request in a single query. \n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI, pydantic_function_tool\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional, List\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(\".env\")\n",
    "\n",
    "AIPROXY_TOKEN = os.getenv(\"AIPROXY_TOKEN\")\n",
    "API_BASE_URL = \"https://aiproxy.sanand.workers.dev/openai/v1\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=AIPROXY_TOKEN,\n",
    "    base_url=API_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class InstallAndRunDatagen(BaseModel):\n",
    "    \"\"\"Model for installing dependencies (if required) and running a Python script.\"\"\"\n",
    "    script_url: str = Field(...,\n",
    "        description=\"URL to the Python script to be downloaded and executed.\"\n",
    "    )\n",
    "\n",
    "    email : str = Field(...,\n",
    "        description=\"The email that is passed as the argument\"\n",
    "    )\n",
    "\n",
    "class FormatMarkdownUsingPrettier(BaseModel):\n",
    "    \"\"\"Model for formatting a Markdown file using Prettier.\"\"\"\n",
    "    file_path: str = Field(..., description=\"Path to the Markdown file to be formatted.\")\n",
    "    prettier_version: str = Field(..., description=\"Version of Prettier to use for formatting. Return Example: 3.4.2 \")\n",
    "\n",
    "\n",
    "class CountTheNumberofDaysAndSave(BaseModel):\n",
    "    day: str = Field(..., description=\"Name of the day\")\n",
    "    input_file: str = Field(..., description=\"Path to the file containing a list of dates.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the count of the days.\")\n",
    "\n",
    "#maybe changed to sort files\n",
    "class SortContacts(BaseModel):\n",
    "    input_file: str = Field(..., description=\"Path to the JSON file containing contacts.\")\n",
    "    output_file: str = Field(..., description=\"Path to the JSON file to write the sorted contacts.\")\n",
    "    sort_keys: List[str] = Field(..., description=\"List of keys to sort by, in order of priority.\")\n",
    "\n",
    "\n",
    "#maybe changed to handle other extension as well\n",
    "class WriteRecentLogs(BaseModel):\n",
    "    directory: str = Field(..., description=\"Path to the directory containing log files.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the recent logs.\")\n",
    "    num_files: int = Field(..., description=\"Number of recent files to process.\")\n",
    "    num_lines: int = Field(..., description=\"Number of lines to extract from each file.\")\n",
    "    extension: str = Field(..., description=\"File extension to filter by, e.g., '.log'.\")\n",
    "\n",
    "#List\n",
    "class GenerateMarkdownIndex(BaseModel):\n",
    "    directory: str = Field(..., description=\"Path to the directory containing Markdown files.\")\n",
    "    output_file: str = Field(..., description=\"Path to the JSON file to write the index.\")\n",
    "    tags: List[str] = Field(..., description=\"List of Markdown tags to extract, e.g., ['#', '##'].\")\n",
    "\n",
    "#maybe changed to pass general text to llm\n",
    "class ExtractUsingLLM(BaseModel):\n",
    "    input_file: str = Field(..., description=\"Path to the file containing the text to be processed.\")\n",
    "    output_file: str = Field(..., description=\"Path to the file to write the extracted information.\")\n",
    "    instructions: str = Field(..., \n",
    "                              description=\"\"\"Instructions for the LLM to extract the desired information.\n",
    "                              Follow the Instruction exactlty. Example: If it says to JUST extract the email: Remember to prompt the tool to just output the email and nothing else.\n",
    "                              \"\"\")\n",
    "\n",
    "\n",
    "class ExtractTextFromImageUsingLLM(BaseModel):\n",
    "    \"\"\"\n",
    "    Model for extracting specific information from an image using an LLM.\n",
    "    \"\"\"\n",
    "    input_image: str = Field(..., description=\"Path to the image file.\")\n",
    "    query: str = Field(..., description=\"\"\"Query specifying what to extract from the image . Specify with or without spaces.).\n",
    "                       Remember to focus on important details.\n",
    "                       \"\"\")\n",
    "    output_file: Optional[str] = Field(..., description=\"Path to the file to write the extracted text. If None, no file will be written.\")\n",
    "\n",
    "\n",
    "class FindMostSimilarTextsUsingEmbeddings(BaseModel):\n",
    "    \"\"\"\n",
    "    Pydantic model for the `find_most_similar_texts` function.\n",
    "    \"\"\"\n",
    "    input_file: str = Field(..., description=\"Path to the file containing the text items, one per line.\")\n",
    "    max_items: Optional[int] = Field(..., description=\"Maximum number of items to process from the file.\")\n",
    "    output_file: Optional[str] = Field(..., description=\"Path to the file to write the most similar pair. If None, output is not written to a file.\")\n",
    "\n",
    "# class CalculateTotalTicketSales(BaseModel):\n",
    "#     database_file: str = Field(..., description=\"Path to the SQLite database file.\")\n",
    "#     output_file: str = Field(..., description=\"Path to the file to write the total sales.\")\n",
    "#     ticket_type: str = Field(..., description=\"The ticket type to calculate total sales for.\")\n",
    "\n",
    "\n",
    "# class FetchDataFromAPI(BaseModel):\n",
    "#     \"\"\"Model for fetching data from an API and saving it to a file.\"\"\"\n",
    "#     api_url: str = Field(..., description=\"The URL of the API to fetch data from.\")\n",
    "#     output_file: str = Field(..., description=\"Path to the file to save the fetched data.\")\n",
    "\n",
    "\n",
    "# class CloneGitRepoAndCommit(BaseModel):\n",
    "#     \"\"\"Model for cloning a Git repository and making a commit.\"\"\"\n",
    "#     repo_url: str = Field(..., description=\"The URL of the Git repository to clone.\")\n",
    "#     commit_message: str = Field(..., description=\"The commit message for the changes.\")\n",
    "#     file_path: Optional[str] = Field(None, description=\"Path to the file to modify before committing.\")\n",
    "#     file_content: Optional[str] = Field(None, description=\"Content to write to the file before committing.\")\n",
    "\n",
    "\n",
    "class RunSQLQuery(BaseModel):\n",
    "    database_file: str = Field(..., description=\"Path to the SQLite or DuckDB database file.\")\n",
    "    query: str = Field(..., description=\"The SQL query to be executed.\")\n",
    "    output_file: Optional[str] = Field(..., description=\"Path to the file to save the query output. If None, no output will be saved.\")\n",
    "    database_type: str = Field(..., description=\"The type of database. Either 'sqlite' or 'duckdb'.\")\n",
    "    output_format: Optional[str] = Field(..., description=\"The format of the output file. Either 'csv' or 'txt'. Defaults to 'csv'.\")\n",
    "\n",
    "\n",
    "# class ExtractDataFromWebsite(BaseModel):\n",
    "#     \"\"\"Model for extracting data from (i.e. scraping) a website.\"\"\"\n",
    "#     website_url: str = Field(..., description=\"The URL of the website to scrape.\")\n",
    "#     output_file: str = Field(..., description=\"Path to the file to save the scraped data.\")\n",
    "#     css_selector: Optional[str] = Field(None, description=\"CSS selector to target specific elements (optional).\")\n",
    "\n",
    "\n",
    "# class CompressOrResizeImage(BaseModel):\n",
    "#     \"\"\"Model for compressing or resizing an image.\"\"\"\n",
    "#     input_image: str = Field(..., description=\"Path to the input image file.\")\n",
    "#     output_image: str = Field(..., description=\"Path to the output image file.\")\n",
    "#     width: Optional[int] = Field(None, description=\"Target width for resizing (optional).\")\n",
    "#     height: Optional[int] = Field(None, description=\"Target height for resizing (optional).\")\n",
    "#     quality: Optional[int] = Field(None, description=\"Quality level for compression (1-100, optional).\")\n",
    "\n",
    "\n",
    "# class TranscribeAudio(BaseModel):\n",
    "#     \"\"\"Model for transcribing audio from an MP3 file.\"\"\"\n",
    "#     audio_file: str = Field(..., description=\"Path to the MP3 audio file to transcribe.\")\n",
    "#     output_file: str = Field(..., description=\"Path to the file to save the transcription text.\")\n",
    "\n",
    "\n",
    "# class ConvertMarkdownToHTML(BaseModel):\n",
    "#     \"\"\"Model for converting Markdown to HTML.\"\"\"\n",
    "#     markdown_file: str = Field(..., description=\"Path to the Markdown file to convert.\")\n",
    "#     output_file: str = Field(..., description=\"Path to the file to save the converted HTML.\")\n",
    "\n",
    "\n",
    "# class WriteAPIEndpointForCSVFilter(BaseModel):\n",
    "#     \"\"\"Model for writing an API endpoint that filters a CSV file and returns JSON data.\"\"\"\n",
    "#     csv_file: str = Field(..., description=\"Path to the CSV file to filter.\")\n",
    "#     filter_column: str = Field(..., description=\"The column name to filter data on.\")\n",
    "#     filter_value: str = Field(..., description=\"The value to filter the column by.\")\n",
    "#     output_file: Optional[str] = Field(None, description=\"Path to save the filtered JSON data (optional).\")\n",
    "\n",
    "class Execute_shell_command(BaseModel):\n",
    "    command: str = Field(..., description=\"Shell commnands to execute in the terminal\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    # A\n",
    "    pydantic_function_tool(InstallAndRunDatagen),\n",
    "    pydantic_function_tool(FormatMarkdownUsingPrettier),\n",
    "    pydantic_function_tool(CountTheNumberofDaysAndSave),\n",
    "    pydantic_function_tool(SortContacts),\n",
    "    pydantic_function_tool(WriteRecentLogs),\n",
    "    pydantic_function_tool(GenerateMarkdownIndex),\n",
    "    pydantic_function_tool(ExtractUsingLLM),\n",
    "    pydantic_function_tool(ExtractTextFromImageUsingLLM),\n",
    "    pydantic_function_tool(FindMostSimilarTextsUsingEmbeddings),\n",
    "    # pydantic_function_tool(CalculateTotalTicketSales),\n",
    "    # B\n",
    "    # pydantic_function_tool(FetchDataFromAPI),\n",
    "    # pydantic_function_tool(CloneGitRepoAndCommit),\n",
    "    pydantic_function_tool(RunSQLQuery),\n",
    "    # pydantic_function_tool(ExtractDataFromWebsite),\n",
    "    # pydantic_function_tool(CompressOrResizeImage),\n",
    "    # pydantic_function_tool(TranscribeAudio),\n",
    "    # pydantic_function_tool(ConvertMarkdownToHTML),\n",
    "    # pydantic_function_tool(WriteAPIEndpointForCSVFilter),\n",
    "    pydantic_function_tool(Execute_shell_command)\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"\"\"\n",
    "/data/credit-card.png contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to /data/credit-card.txt\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\" \n",
    "You are an AI assistant that helps with various tasks. Use the provided functions to complete the user's request.\n",
    "\n",
    "Guidelines:\n",
    "1. Always check whether a tool or dependency is installed before running any command. If it is missing, install it first using the appropriate package manager.\n",
    "2. Assume you are running inside a docker image containing only uv package manager, npm, npx, python and curl.\n",
    "3. Ensure commands are safe and do not exfiltrate data outside `/data`. You must never delete files or data outside `/data`.\n",
    "5. Always verify ambiguous terms in the task description.\n",
    "   - For example, ensure 'uv' refers to the package manager and not `uvicorn`.\n",
    "6. Tasks may be in different languages. Always interpret them correctly.\n",
    "7. Don't mention details like its a credit card, debit card etc that an LLM may refuse to process.\n",
    "         example:\n",
    "               Do not say : \"extract the credit card number and write it without spaces\"\n",
    "               Instead say: \"contains a number. Extract the number, and write it without spaces\"\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": system_prompt},\n",
    "    {\"role\": \"user\", \"content\": task}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=messages,\n",
    "    tools=tools,\n",
    "    tool_choice=\"auto\",\n",
    "    parallel_tool_calls=False,\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-B0o60mTpT84MMvGRyxjUephZ3DNhm', choices=[Choice(finish_reason='tool_calls', index=0, logprobs=None, message=ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4XTUcapXvCJk1NTP16ehAxBi', function=Function(arguments='{\"command\":\"echo \\'30377964378380\\' > /data/credit-card.txt\"}', name='Execute_shell_command'), type='function')]))], created=1739532268, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_13eed4fce1', usage=CompletionUsage(completion_tokens=30, prompt_tokens=1429, total_tokens=1459, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)), monthlyCost=0.2718501999999997, cost=0.004467, monthlyRequests=172)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content=None, refusal=None, role='assistant', audio=None, function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4XTUcapXvCJk1NTP16ehAxBi', function=Function(arguments='{\"command\":\"echo \\'30377964378380\\' > /data/credit-card.txt\"}', name='Execute_shell_command'), type='function')])"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:  Execute_shell_command\n",
      "Args:  {'command': \"echo '30377964378380' > /data/credit-card.txt\"}\n"
     ]
    }
   ],
   "source": [
    "for tool_call in response.choices[0].message.tool_calls:\n",
    "    name = tool_call.function.name\n",
    "    args = json.loads(tool_call.function.arguments)\n",
    "    print(\"Name: \", name)\n",
    "    print(\"Args: \", args)\n",
    "    # result = execute_shell(args)\n",
    "    # messages.append({\n",
    "    #     \"role\": \"tool\",\n",
    "    #     \"tool_call_id\": tool_call.id,\n",
    "    #     \"content\": result\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role': 'tool_calls', 'content' : response.choices[0].message})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': ' \\nYou are an AI assistant that helps with various tasks. Use the provided functions to complete the user\\'s request.\\n\\nGuidelines:\\n1. Always check whether a tool or dependency is installed before running any command. If it is missing, install it first using the appropriate package manager.\\n2. Assume you are running inside a docker image containing only uv package manager, npm, npx, python and curl.\\n3. Ensure commands are safe and do not exfiltrate data outside `/data`. You must never delete files or data outside `/data`.\\n5. Always verify ambiguous terms in the task description.\\n   - For example, ensure \\'uv\\' refers to the package manager and not `uvicorn`.\\n6. Tasks may be in different languages. Always interpret them correctly.\\n7. Don\\'t mention details like its a credit card, debit card etc that an LLM may refuse to process.\\n         example:\\n               Do not say : \"extract the credit card number and write it without spaces\"\\n               Instead say: \"contains a number. Extract the number, and write it without spaces\"\\n\\n\\n'},\n",
       " {'role': 'user',\n",
       "  'content': '\\n/data/credit-card.png contains a credit card number. Pass the image to an LLM, have it extract the card number, and write it without spaces to /data/credit-card.txt\\n'},\n",
       " {'role': 'system',\n",
       "  'content': '[ChatCompletionMessageToolCall(id=\\'call_QHDQn2cDXbNvIHIZx5UeGDw3\\', function=Function(arguments=\\'{\"input_image\":\"/data/credit-card.png\",\"query\":\"extract the number and write it without spaces\",\"output_file\":\"/data/credit-card.txt\"}\\', name=\\'ExtractTextFromImageUsingLLM\\'), type=\\'function\\')]'},\n",
       " {'role': 'system', 'content': 'The extracted number is: 30377964378380'}]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append({'role': 'system', 'content' : \"The extracted number is: 30377964378380\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages[2]= {'role': 'system', 'content' : str(response.choices[0].message.tool_calls)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'role': 'tool', 'content': 'The extracted number is: 30377964378380'}"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
